#!/usr/bin/python
'''
Use ZooKeeper to monitor the status of monitors.  When they come up, assign a putPackages
to each.  When they go down, kill the putPackages

Locks are ephemeral, so no cleanup is needed.
'''
from monitorLibs import szk
from monitorLibs import utils
from monitorLibs import configMgr
import socket
import time
import sys
import logging
import kazoo
import signal
import traceback
import commands
import subprocess
from subprocess import Popen
from threading import Thread, Lock, Condition
class targetWatcher():
    monitor_status_parent = None 
    def __init__(self, slave_count):
        self.lgr = None
        #logging.basicConfig()
        self.cfg = configMgr.configMgr()
        #fh = self.setLogger(self.cfg.logdir)
        self.lgr = utils.getLogger('targetWatcher', self.cfg.logdir)
        hostname = socket.gethostname()
        self.szk = szk.szk(hostname, self.cfg)
        self.lgr.debug('targetWatcher zk client_id %s' % (str(self.szk.zk.client_id)))
        self.lgr.debug('targetWatcher coroner count is %d' % self.cfg.coroner_count)
        #self.szk.setLogger(self.lgr)
        self.lgr.debug('targetWatcher should have set logger for szk??')
        #self.python_dir = self.cfg.python_dir
        signal.signal(signal.SIGINT, self.signal_handler)
        self.target_list = None
        self.myip =  utils.getMyIP()
        self.wait_lock = Lock()
        self.wait_cond = Condition(Lock())
        self.put_pids = {}
        self.slave_count = slave_count

        # paths to monitor status nodes
        self.monitor_status_parent = szk.MONITORS_STATUS_NODE+'/'+self.myip
 
        # set watches on monitors
        self.setMonitorWatch()
        self.stale_locks = []
      
    def waitLock(self, timeout):
        with self.wait_cond:
            current_time = time.time()
            start_time = current_time
            while current_time < start_time + timeout:
                if self.wait_lock.acquire(False):
                    return True
                else:
                    self.wait_cond.wait(timeout - current_time + start_time)
                    current_time = time.time()
        return False

    def getInstance(self, node):
        parts = node.split('_')
        return parts[len(parts)-1]

    def isMonitorUp(self, instance):
        target_name = self.myip+'_'+instance
        node = szk.MONITORS_STATUS_NODE + '/'+self.target_name
        stat = self.szk.zk.exists(node)
        if stat is None:
            return False
        else:
            return True

    '''
    Watch monitor status nodes.  If a monitor comes and then goes away, remove any of the
    locks that it held.
    '''
    def setMonitorWatch(self):
        zk = self.szk.zk
        path = self.monitor_status_parent
        print 'monitor path is '+path
        self.lgr.debug('targetWatcher, setMonitorWatch  monitor status parent path is '+path)
        @zk.ChildrenWatch(path)
        def watch_monitor_children(children):
            if self.target_list is None:
                # first time in, populate list of targets and create putPackages.py
                self.lgr.debug('setMonitorWatch, watch_monitor_children, no target list yet, %d children'% (len(children)))
                self.target_list = []
                for child in children:
                    self.addPut(child)
            else:
                #real_children = self.szk.zk.get_children(self.monitor_status_path)
                print("setMonitorWatch Children are now: %s" % children)
                #print("setMonitorWatch REAL Children are now: %s" % real_children)
                print("and targetList size is %d" % len(self.target_list))
                self.lgr.debug("setMonitorWatch Children are now: %s" % children)
                self.lgr.debug("and targetList size is %d" % len(self.target_list))
                # see if new monitor has come up, if so, create a putPackages.py for it
                self.compareListsToCreate(children)
            # see if a monitor has died, if so, kill its putPackages
            self.compareListsToKill(children)
            return True

    '''
    See if this host should contain a coroner
    '''
    def coronerNeeded(self):
        self.lgr.debug('coronerNeeded, ensure coroners node exists')
        self.szk.zk.ensure_path(szk.CORONERS_NODE)
        retval = False
        if self.slave_count < 2:
            self.lgr.debug('less than 2 slaves, no coronor')
            return False 
        count = self.cfg.coroner_count 
        self.lgr.debug('coronerNeeded, needed count is %d' % count)
        index = 0
        done = False
        while (count > 0) and not done:
             path = szk.CORONERS_NODE+'/coroner_%d' % index
             self.lgr.debug('coronerNeeded, try reading %s' % path)
             try:
                 value, stat = self.szk.zk.get(path)
                 index = index + 1
                 if index >= count or value == self.myip:
                     done = True
             except kazoo.exceptions.NoNodeError:
                 try:
                     self.lgr.debug('coronerNeeded, no node, try create %s' % path)
                     self.szk.zk.create(path, self.myip, ephemeral=True)
                     done = True
                     retval = True
                 except kazoo.exceptions.NodeExistsError:
                     self.lgr.debug('coronerNeeded, was no node, but now there is? %s' % path)
                     pass
        return retval
 

    '''
    Create a putPackage process and record its pid for later killing if needed
    '''
    def addPut(self, child):
        instance = self.getInstance(child)
        self.lgr.debug('targetWatcher, addPut myip: %s cfg.dbg_host: %s, instance: %s  cfg.dbg_instance: %s' % (self.myip, self.cfg.dbg_host,
                 instance, self.cfg.dbg_instance))
        if self.myip == self.cfg.dbg_host and int(instance) >= int(self.cfg.dbg_instance):
            self.lgr.debug('targetWatcher, addPut is dbg monitor, do not create putPackage instance')
            return
        if self.coronerNeeded():
            cmd = 'deathWatch'
            self.lgr.debug('instance %s will be a coroner' % instance)
        else:
            cmd = 'putPackages'
        print 'cmd is '+cmd
        self.lgr.debug('targetWatcher, addPut cmd is '+cmd)
        any_config=''
        if self.cfg.all_configs:
            any_config = 'any_config'
            self.lgr.debug('addPut, using any_config switch to consume all configurations')
        #proc = subprocess.Popen([self.python_dir, cmd, instance], shell=False)
        proc = subprocess.Popen([cmd, instance, any_config], shell=False)
        self.target_list.append(child)
        self.put_pids[instance] = proc
        self.lgr.debug('targetWatcher, addPut back from starting putPackages or deathWatch, pid %d' % proc.pid)

    '''
        Look at the targets that are currently alive & compare to what we had last time.
        If a new target appears, create the putPackage for it.
    '''
    def compareListsToCreate(self, children):
        for child in children:
            if child not in self.target_list:
                self.lgr.debug('create putPackage for %s' % child)
                self.addPut(child)   

    '''
        Look at the monitors that are currently alive & compare to what we have created.
        If a monitor has gone away, kill the putPackage
    '''
    def compareListsToKill(self, children):
        print 'in compare list to kill, target list size is %d' % len(self.target_list)
        self.lgr.debug( 'in compare list to kill, target list size is %d' % len(self.target_list))
        tmp_list = list(self.target_list)
        for target in tmp_list:
            self.lgr.debug('in compare list to kill, look for %s in children  %s' % (target, children))
            if target not in children:
                path = self.monitor_status_parent+'/'+target
                self.lgr.debug('before killing %s, look for the node' % path)
                try:
                    stat = self.szk.zk.exists(path)
                    if stat is not None:
                        self.lgr.debug('%s exits, false alarm' % path)
                        continue
                except kazoo.exceptions.ZookeeperError:
                    self.lgr.debug('zk error of some sort, do not kill yet')
                    continue
                
                instance = self.getInstance(target)
                self.lgr.debug('target %s may have died, kill %d' % (target, self.put_pids[instance].pid))
                self.put_pids[instance].kill()
                self.target_list.remove(target)
                #self.stale_locks.append(target) 
                del self.put_pids[instance]
                #self.wait_lock.release()
                #self.wait_cond.notify()

    def signal_handler(self, signal, frame):
        print ('targetWatcher signal handler')
        self.lgr.debug ('targetWatcher signal handler')
        tb = traceback.format_exc()
        print tb
        try:
            self.wait_lock.release()
        except:
            pass
        sys.exit(1)


    def bye(self):
        self.szk.stop()

    def looper(self):
        got_lock = self.waitLock(2)
        #self.lgr.debug( 'in looper got first lock')
        while True:
            #self.lgr.debug( 'in looper get loop lock')
            got_lock = self.waitLock(2)
            if got_lock and len(self.stale_locks) > 0:
                target = self.stale_locks[len(self.stale_locks)-1]
                self.lgr.debug( 'is a stale lock, remove for '+ target)
                self.szk.removeLocks(szk.FORENSICS, target)
   
def usage():
    print('targetWatcher slave_count')
    exit(1)

if __name__ == "__main__":
    slave_count = None
    if len(sys.argv) < 2:
        usage()
    try:
        slave_count = int(sys.argv[1])
    except:
        usage()
tm = targetWatcher(slave_count)
tm.looper()
tm.bye()
